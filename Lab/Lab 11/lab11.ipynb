{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8c433c4",
   "metadata": {},
   "source": [
    "# Your name and your onyen\n",
    "\n",
    "Classmates you worked with today:\n",
    "\n",
    "- name\n",
    "- name\n",
    "- name\n",
    "  \n",
    "Submit `pdf` + `.ipynb` to Gradescope. No zip file or autograder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dca40",
   "metadata": {},
   "source": [
    "## Part A: Linear regression\n",
    "\n",
    "Let's revisit the ROUSes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed91c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb6aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouses = pd.read_csv('~/110-F25-002/Demos/ROUSes.csv')\n",
    "print(rouses.shape)\n",
    "rouses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279dcf27",
   "metadata": {},
   "source": [
    "Run the following code to drop the column `Temperament` from the table `rouses`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b64843",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouses = rouses.drop(columns='Temperament')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e1f95b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Here our goal is to predict the `Weight` of ROUSes using numerical values. Start by answering the following questions:\n",
    "\n",
    "- Classification or regression? [Your answer]\n",
    "- Predictor variables? [Your answer]\n",
    "- Target variables? [Your answer]\n",
    "- Model: is this simiple or multiple linear regression? [Your answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa73631",
   "metadata": {},
   "source": [
    "### Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2be4950",
   "metadata": {},
   "source": [
    "Run the code `rouses.corr()`. This calculates the correlations between pairs of numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7306e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e73215c",
   "metadata": {},
   "source": [
    "Based on the correlations, which variable do you expect to be more helpful in predicting `Weight`: `Age` or `Length`?\n",
    "\n",
    "[Your answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642d0172",
   "metadata": {},
   "source": [
    "### Setting up the data\n",
    "\n",
    "We usually split the dataset into train and test first and then split them into X and y. But for this exercise, let's go in a different order.\n",
    "\n",
    "Split the table `rouses` into `X` and `y` by completing the following code.\n",
    "\n",
    "```Python\n",
    "y = rouses[...]\n",
    "X = rouses.drop(columns=...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24def5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a230f7",
   "metadata": {},
   "source": [
    "### Setting up regression pipeline\n",
    "\n",
    "We'll write our machine learning code inside a function so that we can call it multiple times later. (We don't expect you to know how Python functions work, but we expect you to see something familiar here.) Copy the following code, then fill in the missing spots marked by `...`.\n",
    "\n",
    "**Hint**: The six `...` are from these options: `X_train`, `X_test`, `y_train`, `y_test`.\n",
    "\n",
    "``` Python\n",
    "def rouses_lr(X, y, seed=0):\n",
    "    # Split X and y into X_train, X_test and y_train, y_test\n",
    "    # using the same seed ensures that the same rows are picked between X and y\n",
    "    \n",
    "    X_train = X.sample(frac=0.8, random_state=seed)\n",
    "    X_test = X.drop(index=X_train.index) \n",
    "    \n",
    "    y_train = y.sample(frac=0.8, random_state=seed)\n",
    "    y_test = y.drop(index=y_train.index)\n",
    "    \n",
    "    # Create \"empty\" model\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    lr = LinearRegression(fit_intercept=True)\n",
    "    \n",
    "    # Fit model to data (or train model)\n",
    "    lr.fit(..., ...)\n",
    "    \n",
    "    # Save coefficients of the trained model\n",
    "    coefs = pd.DataFrame(lr.coef_, \n",
    "                         index=lr.feature_names_in_, \n",
    "                        columns=['Coefficient vals'])\n",
    "    \n",
    "    # Save model performance on train and test\n",
    "    coefs.loc['Train R2 score'] = lr.score(..., ...)\n",
    "    coefs.loc['Test R2 score'] = lr.score(..., ...)\n",
    "``` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d2851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete and run your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd10de0e",
   "metadata": {},
   "source": [
    "### Normalizing features\n",
    "\n",
    "In class, we talked about interpreting linear regression coefficients, and mentioned an important caviat: To use the **magnitude of the coefficients** as an indication of relative feature importance, **the features have to be in the same range or scale**. Today, we'll see a few different ways to acheive that goal. The technical term for this is **feature normalization**, if you want to Google it for your project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb86e749",
   "metadata": {},
   "source": [
    "First, call the function `describe` on the table `X` to see the summary statistics of the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79dc300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf6ff72",
   "metadata": {},
   "source": [
    "Question: Does `Age` and `Length` have the same ranges? Or the same means?\n",
    "\n",
    "[Your answer]\n",
    "\n",
    "We'll see how that affects the final model and interpretation of coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f096dccf",
   "metadata": {},
   "source": [
    "### 1. Standardization\n",
    "\n",
    "The first method is called **standardization**. This means that each variable will have mean of 0 and standard deviation of 1 after this process. You can acheive this by doing the following steps:\n",
    "   1. Within each column, subtract its mean. For example, if the mean `Age` is 13, subtract 13 from everyone's age.\n",
    "   2. Within each column, divide by its standard deviation. For example, if the std of `Age` 10, divide everyone's age by 10.\n",
    "\n",
    "The code to achieve this is very simple. Make sure you understand what's going on, then copy and run the lines below.\n",
    "\n",
    "```Python\n",
    "X_standardized = X - X.mean() # Subtract by column mean\n",
    "X_standardized = X_standardized/X_standardized.std() # Divide by column std\n",
    "\n",
    "X_standardized.describe()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288804d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83435c17",
   "metadata": {},
   "source": [
    "Before we move on, check that each feature in `X_standardized` now has zero mean and 1 stadard deviation as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554aae4",
   "metadata": {},
   "source": [
    "### 2. Min-max scaling\n",
    "\n",
    "The second method is called **min-max scaling**. This makes all values in each column to fall between 0 and 1. The minimum value becomes 0, the maximum value becomes 1, and everything in between is scaled linearly.\n",
    "\n",
    "Here is the code that does that. As before, make sure you understand what's going on.\n",
    "\n",
    "```Python\n",
    "X_minmax = X - X.min() # this turns minimum value of each column to 0\n",
    "ranges = X.max() - X.min() # calculate the range per column\n",
    "X_minmax = X_minmax/ranges # this turns maximum value to 1\n",
    "\n",
    "X_minmax.describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41892a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f307d9dd",
   "metadata": {},
   "source": [
    "Before we move on, check that each feature in `X_minimax` now has minimum 0 and maximum 1 as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1128bd",
   "metadata": {},
   "source": [
    "### Check the results!\n",
    "\n",
    "Finally it's time to put everything together. Run the following code to check:\n",
    "\n",
    "rows: \n",
    "- the resulting coefficients (`Age`, `Length`) of the linear regression model, and the\n",
    "- $R^2$ scores (`Train R2 score`, `Test R2 score`), for\n",
    "\n",
    "columns:\n",
    "- the three different versions of feature tables (unnormalized `X`, standardized `X_standardized`, min-max scaled `X_minmax`), and\n",
    "- the unnormalized coefficients muliplied by the std of the unnormalized features (`Unnormalized * std`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0daca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for features, name in zip([X, X_standardized, X_minmax], \n",
    "                    [\"Unnormalized\", \"Standardized\", \"Min-max scaled\"]):\n",
    "    res = rouses_lr(features, y, seed)\n",
    "    res = res.rename(columns ={'Coefficient vals': name})\n",
    "    results = pd.concat((results, res), axis=1)\n",
    "\n",
    "results['Unnormalized * std'] = results['Unnormalized']*X.std()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f5efac",
   "metadata": {},
   "source": [
    "The last column is sometimes called **beta** or **standardized** coefficients. Does it look similar to any of the other columns?\n",
    "\n",
    "Question: Which feature is more important, according to the magnitude of the coefficients? Did that answer change for different versions of features?\n",
    "\n",
    "[Your answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f626de8f",
   "metadata": {},
   "source": [
    "I hope this convinces you to normalize your features for your project if you decide to do a predictive model, and especially if you plan to do linear regression.\n",
    "\n",
    "FYI, you get the same score regardless of feature normalization here. This is not the case for every dataset and every ML model. Often normalization improves accuracy of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
